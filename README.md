<p align="center">
  <img src="images/sample.png" alt="Generador de Novelas de FantasÃ­a con LLMs" width="800">
  <h1 align="center">ğŸ“š Generador de Novelas de FantasÃ­a con LLMs</h1>
</p>

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue?style=flat-square)

## âœ¨ IntroducciÃ³n

Este proyecto utiliza Large Language Models (LLMs) para generar novelas de fantasÃ­a completas con transparencia del proceso creativo.

> **âš ï¸ AVISO**: Proyecto en fase temprana de desarrollo. Pueden existir bugs y limitaciones.

> **âš ï¸ AVISO SOBRE CONTEXTO**: Se recomienda utilizar modelos con capacidad de 128.000 tokens de contexto hasta que los problemas actuales de manejo de contexto sean solucionados. Modelos con menor capacidad pueden experimentar pÃ©rdida de coherencia narrativa entre capÃ­tulos.

---

## ğŸ†• Actualizaciones recientes (Mayo 2025)

- ğŸ’» **Modo comando mejorado**: Ahora puedes seleccionar modelos directamente con `--model` y listar los disponibles con `--list-models`
- ğŸ“ **Nuevo sistema de resÃºmenes entre capÃ­tulos** para mejorar la coherencia narrativa
- ğŸ”„ **Flujo narrativo mejorado** con contexto enriquecido para continuidad entre secciones
- ğŸ“Š **Formateo profesional de documentos** con metadatos, mÃ¡rgenes y estilos optimizados
- ğŸ“‘ **Mejor organizaciÃ³n textual** con procesamiento semÃ¡ntico de pÃ¡rrafos
- ğŸ§  **Sistema de detecciÃ³n de modelos multi-API**: Detecta automÃ¡ticamente modelos disponibles en Ollama, OpenAI, DeepSeek, Groq y proveedores personalizados
- ğŸ”§ **ConfiguraciÃ³n flexible mediante archivo .env**: Personaliza completamente todos los proveedores y modelos sin tocar el cÃ³digo
- ğŸ¨ **VisualizaciÃ³n mejorada de pensamientos**: Los pensamientos del modelo ahora se muestran correctamente en amarillo y cambian a azul al terminar
- ğŸ–¥ï¸ Interfaz web cyberpunk completamente rediseÃ±ada
- ğŸ“ VisualizaciÃ³n en tiempo real del proceso de generaciÃ³n, separando pensamientos y resultados finales
- ğŸ“Š Barra de progreso visual para seguimiento detallado
- ğŸ“‹ OrganizaciÃ³n clara del contenido generado
- ğŸ¨ Efectos visuales mejorados para una experiencia mÃ¡s inmersiva
- ğŸ“² DiseÃ±o responsivo adaptado a diferentes dispositivos

---

## ğŸš€ CaracterÃ­sticas Principales

- ğŸ§  Soporte multi-API (Ollama, OpenAI, DeepSeek, Groq, Anthropic)
- ğŸ“– GeneraciÃ³n completa de estructuras narrativas y personajes
- ğŸ¨ Interfaz cyberpunk con visualizaciÃ³n en tiempo real
- ğŸ“ Sistema de resÃºmenes para coherencia narrativa
- ğŸ“¤ ExportaciÃ³n a PDF/DOCX con formato profesional
- âš™ï¸ ConfiguraciÃ³n flexible mediante archivo `.env`
- ğŸ” Transparencia del proceso con pensamientos del modelo

---

## ğŸ–¥ï¸ Demo Interactiva

![Interfaz del Generador](images/sample.png)

---

## âš™ï¸ ConfiguraciÃ³n RÃ¡pida

git clone [https://github.com/kroryan/Generador-de-libros-IA-cli](https://github.com/kroryan/Generador-de-libros-IA-cli).git
cd Generador-de-libros-IA-cli
pip install -r requirements.txt
python src/app.py --web  #se iniciara el modo web, este modo no es recomendado ya que la web aun no esta muy pulida tambien puedes usar 
Visita `http://localhost:5000`

o tambien para la consola:

 python src/app.py 

---

## ğŸ’» Uso en LÃ­nea de Comandos

El programa ahora ofrece una interfaz de lÃ­nea de comandos mejorada con selecciÃ³n explÃ­cita de modelos:

### ğŸ“‹ Opciones disponibles

- **Listar modelos disponibles**:
  ```bash
  python app.py --list-models
  ```

- **Generar libro con un modelo especÃ­fico**:
  ```bash
  python app.py --model groq:llama3-8b-8192
  ```

- **Iniciar interfaz web con un modelo preseleccionado**:
  ```bash
  python app.py --web --model openai:gpt-4
  ```

  ```bash
  python app.py --web --model groq:qwen-qwq-32b
  ```

### ğŸ”§ InteracciÃ³n con el archivo .env

- Si no especificas un modelo con `--model`, el programa usarÃ¡ el valor de `MODEL_TYPE` del archivo `.env`
- Puedes configurar tu archivo `.env` para establecer un modelo predeterminado:
  ```
  MODEL_TYPE=groq
  GROQ_MODEL=llama3-8b-8192
  GROQ_API_KEY=tu_clave_api
  ```

- La prioridad de selecciÃ³n de modelos es:
  1. Modelo especificado con `--model`
  2. Valor de `MODEL_TYPE` en `.env`
  3. Fallback a otros proveedores configurados

---

## ğŸ› ï¸ GuÃ­a de Prompts

### ğŸ” UbicaciÃ³n de los Prompts

| Archivo               | Clase                 | PropÃ³sito |
|-----------------------|-----------------------|-----------|
| `structure.py`        | `TitleChain`          | TÃ­tulo del libro |
| `structure.py`        | `FrameworkChain`      | Marco narrativo |
| `ideas.py`            | `IdeasChain`          | Desarrollo de ideas |
| `writing.py`          | `WriterChain`         | Escritura narrativa |

### ğŸ“ PersonalizaciÃ³n de Prompts

1. Edite el archivo correspondiente
2. Busque `PROMPT_TEMPLATE`
3. Modifique manteniendo los marcadores `{variables}`

**Ejemplo para estilo poÃ©tico** (`writing.py`):
```python
PROMPT_TEMPLATE = """
Eres un poeta y escritor de fantasÃ­a en espaÃ±ol.
Utiliza lenguaje metafÃ³rico y descripciones vÃ­vidas.
...
"""
```

---

## ğŸŒ Proveedores Compatibles

| Proveedor       | Modelos Ejemplo         | Requisitos         | Contexto Recomendado |
|-----------------|-------------------------|--------------------|----------------------|
| Ollama (Local)  | llama3, mistral         | Servidor Ollama    | 8K-32K tokens        |
| OpenAIcompatible| GPT-4, GPT-3.5          | API Key            | 8K-128K tokens       |
| Groq            | Mixtral-8x7b            | API Key            | 32K tokens           |
| Anthropic       | Claude-3                | API Key + librerÃ­a | 100K+ tokens         |

> **ğŸ’¡ Nota sobre contexto**: Para una generaciÃ³n Ã³ptima, se recomienda usar modelos con al menos 128K tokens de contexto. Modelos con menor capacidad pueden requerir configuraciones adicionales o experimentar limitaciones en la coherencia narrativa.

---

## âš™ï¸ ConfiguraciÃ³n .env

```env
# Ollama
OLLAMA_MODEL=llama3
OLLAMA_API_BASE=http://localhost:11434

# OpenAI
OPENAI_API_KEY=tu_clave
OPENAI_MODEL=gpt-4
```

---

## ğŸš§ Proceso de GeneraciÃ³n

1. **Estructura (20%)**: TÃ­tulo y marco narrativo
2. **Ideas (40%)**: Desarrollo de capÃ­tulos
3. **Escritura (85%)**: Narrativa detallada
4. **PublicaciÃ³n (100%)**: ExportaciÃ³n a PDF/DOCX

---

## ğŸš§ Desarrollo Futuro

- âœ… Soporte para parÃ¡metros avanzados
- âœ… IntegraciÃ³n con mÃ¡s proveedores
- âœ… GeneraciÃ³n de imÃ¡genes
- â³ OptimizaciÃ³n avanzada del manejo de contexto para modelos con ventanas mÃ¡s pequeÃ±as
- â³ ImplementaciÃ³n de memoria persistente para mejorar la coherencia en libros largos

---

Si por alguna razon quereis contactarme podeis hacerlo entrando a este discord, mi nombre es allen en el discord; https://discord.gg/TTmrXaeXM8