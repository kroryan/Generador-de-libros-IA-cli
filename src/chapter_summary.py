from utils import BaseEventChain, print_progress, clean_think_tags, extract_content_from_llm_response

class ChapterSummaryChain(BaseEventChain):
    """Genera res√∫menes de cap√≠tulos para mantener la coherencia narrativa entre ellos."""
    
    PROMPT_TEMPLATE = """
    Como editor profesional, crea un resumen breve y esencial del siguiente cap√≠tulo.
    El resumen debe capturar SOLO los elementos m√°s importantes para mantener coherencia.
    
    IMPORTANTE: El resumen debe estar en espa√±ol y ser muy conciso (m√°ximo 150 palabras).
    
    T√≠tulo del libro: {title}
    Cap√≠tulo: {chapter_title} (Cap√≠tulo {chapter_num} de {total_chapters})
    
    Contenido del cap√≠tulo:
    {chapter_content}
    
    <think>
    Identificar√© solo los elementos narrativos cruciales:
    1. Eventos principales que afectan la trama general
    2. Desarrollo significativo de personajes principales
    3. Revelaciones importantes o giros en la trama
    4. Elementos espec√≠ficos que necesitar√°n continuidad
    
    Ser√© extremadamente conciso y preciso, enfoc√°ndome solo en lo esencial.
    </think>
    
    Genera un resumen breve y esencial:"""

    # Prompt para resumir incremental por secciones
    PROGRESSIVE_SUMMARY_TEMPLATE = """
    Actualiza el resumen existente para incorporar solo los elementos esenciales 
    de la nueva secci√≥n. Mant√©n el resumen muy breve y centrado solo en lo crucial.
    
    IMPORTANTE: M√°ximo 150 palabras, solo en espa√±ol.
    
    T√≠tulo: {title}
    Cap√≠tulo: {chapter_title} (Cap√≠tulo {chapter_num})
    
    Resumen actual:
    {current_summary}
    
    Nueva secci√≥n:
    {new_section}
    
    <think>
    Analizar√© qu√© elementos nuevos son verdaderamente importantes:
    - ¬øIntroduce alg√∫n evento cr√≠tico para la trama?
    - ¬øRevela informaci√≥n esencial sobre personajes principales?
    - ¬øPresenta un giro o cambio significativo?
    
    Incorporar√© solo lo verdaderamente relevante, manteniendo el resumen muy conciso.
    </think>
    
    Resumen actualizado:"""

    def extract_key_segments(self, text, max_segments=3, segment_length=1000):
        """
        Extrae segmentos clave del texto (inicio, medio y final) de manera m√°s eficiente
        con segmentos m√°s peque√±os.
        """
        if len(text) <= segment_length * max_segments:
            return text
            
        segments = []
        
        # Incluir inicio (establece personajes y escenario)
        segments.append(text[:segment_length])
        
        # Si hay espacio para m√°s de 2 segmentos, incluir segmento del medio
        if max_segments > 2:
            # Extraer una secci√≥n del medio
            middle_pos = len(text) // 2
            middle_start = max(middle_pos - segment_length // 2, segment_length)
            middle_end = min(middle_start + segment_length, len(text) - segment_length)
            segments.append(text[middle_start:middle_end])
        
        # Incluir final (resoluciones, giros finales)
        segments.append(text[-segment_length:])
        
        # Unir los segmentos con indicadores claros
        result = "INICIO DEL CAP√çTULO:\n" + segments[0]
        
        for i in range(1, len(segments) - 1):
            result += f"\n\n[...PARTE MEDIA DEL CAP√çTULO...]\n\n{segments[i]}"
            
        result += f"\n\n[...FINAL DEL CAP√çTULO...]\n\n{segments[-1]}"
            
        return result

    def update_summary_incrementally(self, title, chapter_num, chapter_title, current_summary, new_section, total_chapters):
        """Actualiza un resumen existente incorporando nueva informaci√≥n esencial"""
        print_progress(f"Actualizando resumen incremental del cap√≠tulo {chapter_num}...")
        
        # Si no hay resumen actual, crear uno b√°sico
        if not current_summary or current_summary.strip() == "":
            current_summary = f"Inicio del cap√≠tulo {chapter_num} ({chapter_title})."
        
        try:
            # Extraer solo fragmentos clave de la nueva secci√≥n
            if len(new_section) > 1500:
                # Tomar solo inicio y final (donde suele estar la informaci√≥n clave)
                summary_section = new_section[:750] + "\n\n[...]\n\n" + new_section[-750:]
            else:
                summary_section = new_section
                
            # Nota: El error era que aqu√≠ se esperaban par√°metros no proporcionados
            # Cambiamos para usar el template directamente con los par√°metros correctos
            result = self.invoke(
                title=clean_think_tags(title),
                chapter_num=chapter_num,
                chapter_title=clean_think_tags(chapter_title),
                current_summary=clean_think_tags(current_summary),
                new_section=clean_think_tags(summary_section)
            )
            
            if not result:
                raise ValueError("No se gener√≥ contenido v√°lido para el resumen")
                
            # Limitar longitud del resumen incremental para evitar crecimiento excesivo
            if len(result) > 500:
                print_progress("Resumen demasiado largo, truncando...")
                result = result[:500] + "..."
                
            return result
            
        except Exception as e:
            print_progress(f"Error actualizando resumen incremental: {str(e)}")
            return current_summary  # Devolver el resumen anterior sin cambios
    
    def run(self, title, chapter_num, chapter_title, chapter_content, total_chapters):
        """Genera un resumen final conciso del cap√≠tulo"""
        print_progress(f"Generando resumen final del cap√≠tulo {chapter_num}: {chapter_title}")
        
        try:
            # Preparar el contenido de manera m√°s eficiente
            summarized_content = self.extract_key_segments(chapter_content, 
                                                          max_segments=3, 
                                                          segment_length=1000)
                
            result = self.invoke(
                title=clean_think_tags(title),
                chapter_num=chapter_num,
                chapter_title=clean_think_tags(chapter_title),
                chapter_content=clean_think_tags(summarized_content),
                total_chapters=total_chapters
            )
            
            if not result:
                raise ValueError("No se gener√≥ contenido v√°lido para el resumen")
            
            # Limitar longitud del resumen final para no sobrecargar el contexto
            if len(result) > 300:
                print_progress("Resumen final demasiado largo, truncando...")
                result = result[:300] + "..."
                
            print_progress(f"Resumen final del cap√≠tulo {chapter_num} completado")
            return result
            
        except Exception as e:
            print_progress(f"Error generando resumen para el cap√≠tulo {chapter_num}: {str(e)}")
            return f"Cap√≠tulo {chapter_num}: Contin√∫a la historia."

class ProgressiveContextManager:
    """
    Administra el contexto proporcionado al modelo de manera progresiva y minimalista,
    adapt√°ndose a modelos con diferentes capacidades de contexto como Gemma 9B.
    """
    
    def __init__(self, title, framework, total_chapters, model_capacity="standard"):
        self.title = title
        self.framework = self._create_minimal_framework(framework)
        self.total_chapters = total_chapters
        self.chapter_summaries = {}
        self.incremental_summaries = {}
        # Clasificaci√≥n de capacidad del modelo: "limited" (como Gemma 9B), "standard", "extended"
        self.model_capacity = model_capacity
        # Historial de contexto reciente para cap√≠tulos
        self.recent_context_history = {}
        # Cach√© para res√∫menes ultra compactos
        self.ultra_compact_cache = {}
        # Factor de ajuste por capacidad de modelo (en tokens aproximados)
        self.model_capacity_tokens = {
            "limited": 8000,    # Para modelos como Gemma 9B
            "standard": 16000,  # Para modelos est√°ndar
            "extended": 32000   # Para modelos con contexto extendido
        }
        # Seguimiento de uso de tokens
        self.token_usage_history = []
        # Umbral para compresi√≥n agresiva (% del presupuesto total)
        self.aggressive_compression_threshold = 0.75

    def _estimate_tokens(self, text):
        """
        Estima el n√∫mero de tokens en un texto para controlar el uso de contexto.
        Esta es una estimaci√≥n aproximada - 4 caracteres ‚âà 1 token para ingl√©s,
        pero para espa√±ol usamos un factor un poco menor (3.5 caracteres).
        """
        if not text:
            return 0
            
        # Factores de conversi√≥n aproximados por idioma
        chars_per_token = 3.5  # Para espa√±ol
        
        # Ajuste por espacios y puntuaci√≥n
        whitespace_count = len([c for c in text if c.isspace()])
        punctuation_count = len([c for c in text if c in ".,;:!?-()[]{}\"'"])
        
        # Los espacios y signos suelen contar como tokens separados en algunos modelos
        adjusted_length = len(text) + (whitespace_count * 0.2) + (punctuation_count * 0.3)
        estimated_tokens = adjusted_length / chars_per_token
        
        return int(estimated_tokens)
        
    def _get_available_context_budget(self):
        """
        Calcula el presupuesto de tokens disponible seg√∫n la capacidad del modelo,
        reservando espacio para la respuesta y sistema.
        """
        total_capacity = self.model_capacity_tokens.get(self.model_capacity, 16000)
        
        # Reservar aproximadamente 30% para la respuesta y sistema
        available_budget = int(total_capacity * 0.7)
        
        return available_budget
    
    def _create_minimal_framework(self, framework):
        """Crea una versi√≥n m√≠nima del marco narrativo con solo puntos clave"""
        # Extraer solo informaci√≥n esencial del framework
        if len(framework) > 500:
            lines = framework.split('\n')
            essential_lines = []
            
            key_terms = [
                "protagonista", "personaje principal", "antagonista", 
                "conflicto central", "objetivo principal", "mundo", 
                "premisa", "trama principal"
            ]
            
            # Extraer solo l√≠neas con informaci√≥n clave
            for line in lines:
                line = line.strip()
                if any(term in line.lower() for term in key_terms):
                    essential_lines.append(line)
            
            # Si no encontramos suficientes l√≠neas esenciales, tomar algunas principales
            if len(essential_lines) < 3:
                return "\n".join(lines[:3])
                
            return "\n".join(essential_lines[:5])  # Limitar a m√°ximo 5 l√≠neas
        return framework
    
    def _extract_framework_essence(self, framework):
        """Extrae la esencia m√≠nima del marco para modelos con contexto limitado"""
        if not framework:
            return ""
            
        # Para modelos limitados, extraer solo 2-3 conceptos clave
        key_phrases = []
        lines = framework.split('\n')
        
        # Identificar las frases m√°s cruciales
        for line in lines:
            line = line.strip()
            if "protagonista:" in line.lower() or "conflicto:" in line.lower() or "premisa:" in line.lower():
                key_phrases.append(line)
                
        # Si no encontramos frases clave, tomar las primeras 2 l√≠neas
        if not key_phrases and len(lines) > 0:
            return "\n".join(lines[:2])
            
        # Limitar a 2-3 frases clave para contexto muy limitado
        return "\n".join(key_phrases[:3])
    
    def add_chapter_summary(self, chapter_num, chapter_key, summary):
        """A√±ade el resumen de un cap√≠tulo a la memoria contextual"""
        # Para modelos con contexto limitado, reducir a√∫n m√°s los res√∫menes
        if self.model_capacity == "limited" and len(summary) > 150:
            summary = self._create_ultra_condensed_summary(summary)
            
        self.chapter_summaries[chapter_key] = summary
        
        # Mantener tambi√©n un registro de los res√∫menes m√°s recientes
        # con mayor detalle para los √∫ltimos cap√≠tulos
        self.recent_context_history[chapter_key] = {
            "summary": summary,
            "chapter_num": chapter_num,
            "last_accessed": 0  # Contador para seguimiento de acceso
        }
    
    def _create_ultra_condensed_summary(self, summary):
        """Crea un resumen ultra condensado para modelos con capacidad limitada"""
        if not summary:
            return ""
            
        # Mejora: implementar t√©cnica de reducci√≥n de tokens m√°s agresiva
        if len(summary) < 100:
            return summary
            
        # Para res√∫menes largos, aplicar compresi√≥n agresiva
        sentences = summary.split('. ')
        
        # Seleccionar solo primera y √∫ltima oraci√≥n si hay m√°s de 3
        if len(sentences) > 3:
            key_sentences = [sentences[0], sentences[-1]]
            condensed = '. '.join(key_sentences)
            
            # Eliminar palabras menos importantes para reducir a√∫n m√°s
            stop_words = ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas', 'y', 'e', 'o', 'u', 'que', 'como', 'cuando', 'donde']
            for word in stop_words:
                condensed = condensed.replace(f' {word} ', ' ')
                
            return condensed + '.'
        
        # Para res√∫menes cortos, eliminar solo palabras de relleno
        else:
            condensed = summary
            stop_words = ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas']
            for word in stop_words:
                condensed = condensed.replace(f' {word} ', ' ')
            return condensed
    
    def get_incremental_summary(self, chapter_num, chapter_key):
        """Obtiene el resumen incremental actual para un cap√≠tulo espec√≠fico"""
        return self.incremental_summaries.get(chapter_key, "")
        
    def update_incremental_summary(self, chapter_num, chapter_key, summary):
        """Actualiza el resumen incremental para un cap√≠tulo espec√≠fico"""
        # Para modelos con contexto limitado, condensar a√∫n m√°s
        if self.model_capacity == "limited" and len(summary) > 150:
            summary = self._create_ultra_condensed_summary(summary)
            
        self.incremental_summaries[chapter_key] = summary
        
    def get_context_for_section(self, current_chapter, section_position, chapter_key):
        """
        Obtiene un contexto progresivo y adaptativo seg√∫n la posici√≥n actual y tipo de modelo.
        """
        # Actualizar contadores de acceso para implementar ventana deslizante
        self._update_access_counters(current_chapter)
        
        # Determinar n√∫mero de cap√≠tulos a incluir seg√∫n capacidad del modelo
        num_relevant_chapters = self._get_relevant_chapter_count()
        
        # 1. Obtener solo los cap√≠tulos m√°s relevantes 
        relevant_chapters = self._get_most_relevant_chapters(current_chapter, num_relevant_chapters)
        
        # 2. Preparar un resumen adaptativo de cap√≠tulos anteriores
        previous_chapters_summary = self._create_adaptive_previous_summary(relevant_chapters)
        
        # 3. Adaptar el framework seg√∫n posici√≥n y capacidad del modelo
        adjusted_framework = self._get_adapted_framework(current_chapter, section_position)
            
        # 4. Incluir solo pistas espec√≠ficas seg√∫n la posici√≥n
        position_context = self._get_position_specific_context(section_position, current_chapter)
        
        # 5. Resumen incremental del cap√≠tulo actual (si existe)
        current_chapter_summary = ""
        if chapter_key in self.incremental_summaries and self.incremental_summaries[chapter_key]:
            current_chapter_summary = f"Progreso actual: {self.incremental_summaries[chapter_key]}"
            
        return {
            "framework": adjusted_framework,
            "previous_chapters_summary": previous_chapters_summary,
            "position_context": position_context,
            "current_chapter_summary": current_chapter_summary
        }
    
    def _update_access_counters(self, current_chapter):
        """Actualiza contadores de acceso para implementar ventana deslizante de contexto"""
        for chapter_key, data in self.recent_context_history.items():
            # Incrementar todos los contadores
            data["last_accessed"] += 1
            
            # Para el cap√≠tulo inmediatamente anterior, resetear contador
            if data["chapter_num"] == current_chapter - 1:
                data["last_accessed"] = 0
                
            # Para el primer cap√≠tulo, mantener contador bajo
            if data["chapter_num"] == 1:
                data["last_accessed"] = min(data["last_accessed"], 3)
                
    def _get_relevant_chapter_count(self):
        """Determina cu√°ntos cap√≠tulos incluir seg√∫n capacidad del modelo"""
        if self.model_capacity == "limited":  # Modelos como Gemma 9B
            return 2  # Solo 1-2 cap√≠tulos m√°s relevantes
        elif self.model_capacity == "standard":
            return 3  # 2-3 cap√≠tulos relevantes
        else:  # Para modelos con contexto extendido
            return 4  # Hasta 4 cap√≠tulos relevantes
    
    def _create_adaptive_previous_summary(self, relevant_chapters):
        """Crea un resumen adaptativo de cap√≠tulos previos seg√∫n capacidad del modelo"""
        if not relevant_chapters:
            return ""
            
        # Para modelos con contexto limitado, formato ultra conciso
        if self.model_capacity == "limited":
            previous_chapters_summary = "Esencial de cap√≠tulos previos:\n"
            for ch_key in relevant_chapters:
                if ch_key in self.chapter_summaries:
                    # Solo 1-2 frases para modelos limitados
                    summary = self.chapter_summaries[ch_key]
                    if len(summary) > 100:
                        # Extraer solo las primeras frases
                        sentences = summary.split('.')
                        if len(sentences) > 2:
                            summary = sentences[0].strip() + "."
                    
                    previous_chapters_summary += f"- {ch_key.split(':')[0]}: {summary}\n"
        else:
            # Para modelos est√°ndar, formato m√°s completo
            previous_chapters_summary = "Resumen de cap√≠tulos relevantes:\n"
            for ch_key in relevant_chapters:
                if ch_key in self.chapter_summaries:
                    previous_chapters_summary += f"- {ch_key}: {self.chapter_summaries[ch_key]}\n"
        
        return previous_chapters_summary
    
    def _get_adapted_framework(self, current_chapter, section_position):
        """Obtiene una versi√≥n del framework adaptada a la posici√≥n y capacidad del modelo"""
        # Para cap√≠tulos iniciales, proporcionar m√°s contexto del framework
        if current_chapter <= 2:
            if self.model_capacity == "limited":
                return self._extract_framework_essence(self.framework)
            else:
                return self.framework
                
        # Para cap√≠tulos intermedios, reducir framework
        elif current_chapter < self.total_chapters - 1:
            if self.model_capacity == "limited":
                # Solo una frase clave para modelos limitados
                framework_lines = self.framework.split('\n')
                if len(framework_lines) > 0:
                    return framework_lines[0]
                return ""
            else:
                # Versi√≥n reducida para modelos est√°ndar
                framework_lines = self.framework.split('\n')
                if len(framework_lines) > 2:
                    return "\n".join(framework_lines[:2])
                return self.framework
                
        # Para cap√≠tulos finales, incluir pistas de resoluci√≥n
        else:
            if self.model_capacity == "limited":
                return "Recuerda resolver la trama principal."
            else:
                return "Resuelve las tramas pendientes siguiendo el marco narrativo original."
    
    def _get_position_specific_context(self, section_position, current_chapter):
        """Obtiene contexto espec√≠fico seg√∫n la posici√≥n en el cap√≠tulo"""
        if section_position == "inicio":
            if current_chapter > 1:
                return "Conecta con eventos del cap√≠tulo anterior."
            else:
                return "Introduce personajes y escenario principal."
        elif section_position == "medio":
            return "Desarrolla conflicto principal de este cap√≠tulo."
        elif section_position == "final":
            if current_chapter < self.total_chapters:
                return "Prepara elementos clave para el siguiente cap√≠tulo."
            else:
                return "Cierra la historia resolviendo conflictos principales."
        return ""
    
    def _get_most_relevant_chapters(self, current_chapter, max_chapters=2):
        """
        Implementa una ventana deslizante para obtener solo los cap√≠tulos m√°s relevantes,
        priorizando cap√≠tulos recientes y cap√≠tulos importantes (1er cap√≠tulo).
        """
        if not self.chapter_summaries:
            return []
            
        # Convertir chapter_summaries a una lista ordenada por n√∫mero de cap√≠tulo
        all_chapter_keys = sorted(self.chapter_summaries.keys(), 
                               key=lambda x: int(x.split(':')[0].replace('Cap√≠tulo ', '')))
        
        relevant_keys = []
        
        # 1. Siempre incluir cap√≠tulo inmediatamente anterior si existe
        if current_chapter > 1 and len(all_chapter_keys) >= current_chapter - 1:
            previous_chapter_key = all_chapter_keys[current_chapter - 2]  # -2 por √≠ndice 0
            relevant_keys.append(previous_chapter_key)
        
        # 2. Para cap√≠tulos posteriores, a√±adir primer cap√≠tulo (establece premisas)
        if current_chapter > 3 and len(all_chapter_keys) > 0:
            relevant_keys.append(all_chapter_keys[0])
            
        # 3. Para la ventana deslizante, a√±adir cap√≠tulos con menor contador de acceso
        if len(all_chapter_keys) > 2 and len(relevant_keys) < max_chapters:
            # Ordenar historial de acceso por contador (menor = m√°s reciente/relevante)
            sorted_by_access = sorted(
                [(k, self.recent_context_history.get(k, {"last_accessed": 999})["last_accessed"]) 
                for k in all_chapter_keys if k not in relevant_keys],
                key=lambda x: x[1]
            )
            
            # A√±adir cap√≠tulos hasta alcanzar el m√°ximo permitido
            for ch_key, _ in sorted_by_access:
                if len(relevant_keys) >= max_chapters:
                    break
                if ch_key not in relevant_keys:
                    relevant_keys.append(ch_key)
        
        return relevant_keys
        
    def set_model_capacity(self, capacity):
        """
        Establece la capacidad del modelo para ajustar estrategias de contexto.
        capacity: "limited" (como Gemma 9B), "standard", "extended"
        """
        if capacity in ["limited", "standard", "extended"]:
            self.model_capacity = capacity

    def visualize_token_usage(self, context_dict):
        """
        Visualiza el uso de tokens en el contexto actual y genera advertencias
        cuando se acerca al l√≠mite del modelo.
        
        Args:
            context_dict: Diccionario con las diferentes partes del contexto
            
        Returns:
            dict: Estad√≠sticas de uso de tokens y advertencias
        """
        import sys
        
        # Calcular tokens por cada componente de contexto
        token_usage = {}
        total_tokens = 0
        
        for key, content in context_dict.items():
            if not content:
                token_usage[key] = 0
                continue
                
            tokens = self._estimate_tokens(content)
            token_usage[key] = tokens
            total_tokens += tokens
        
        # A√±adir al historial para seguimiento
        self.token_usage_history.append(total_tokens)
        if len(self.token_usage_history) > 10:
            self.token_usage_history.pop(0)  # Mantener solo los 10 m√°s recientes
            
        # Calcular porcentaje del presupuesto disponible
        available_budget = self._get_available_context_budget()
        usage_percentage = (total_tokens / available_budget) * 100
        
        # Generar visualizaci√≥n
        result = {
            "total_tokens": total_tokens,
            "available_budget": available_budget,
            "usage_percentage": round(usage_percentage, 1),
            "component_usage": token_usage,
            "warnings": []
        }
        
        # Generar advertencias si es necesario
        if usage_percentage > 90:
            result["warnings"].append("¬°CR√çTICO! Uso de contexto extremadamente alto")
        elif usage_percentage > 75:
            result["warnings"].append("ADVERTENCIA: Uso de contexto alto, considere comprimir m√°s")
            
        # Si el uso ha aumentado significativamente desde la √∫ltima vez
        if len(self.token_usage_history) > 1 and total_tokens > self.token_usage_history[-2] * 1.2:
            result["warnings"].append("ALERTA: Crecimiento r√°pido del contexto detectado")
            
        # Imprimir visualizaci√≥n en modo de depuraci√≥n
        if 'debug' in sys.argv or self.model_capacity == "limited":
            print(f"\n--- üìä Uso de contexto ({self.model_capacity}) ---")
            print(f"Total: {total_tokens} tokens ({usage_percentage:.1f}% del presupuesto)")
            print(f"Framework: {token_usage.get('framework', 0)} tokens")
            print(f"Res√∫menes previos: {token_usage.get('previous_chapters_summary', 0)} tokens")
            print(f"Cap√≠tulo actual: {token_usage.get('current_chapter_summary', 0)} tokens")
            for warning in result["warnings"]:
                print(f"‚ö†Ô∏è {warning}")
            print("-----------------------------------\n")
            
        return result
        
    def apply_adaptive_compression(self, context_dict):
        """
        Aplica compresi√≥n adaptativa al contexto basado en el uso actual de tokens
        y la capacidad del modelo, especialmente √∫til para Gemma 9B.
        
        Args:
            context_dict: Diccionario con componentes del contexto
            
        Returns:
            dict: Contexto comprimido adaptado a la capacidad del modelo
        """
        # Analizar uso actual
        usage_stats = self.visualize_token_usage(context_dict)
        
        # Si estamos por debajo del umbral, no comprimir
        if usage_stats["usage_percentage"] < 70:
            return context_dict
            
        compressed_context = context_dict.copy()
        
        # Para modelos limitados o cuando se excede el umbral
        if self.model_capacity == "limited" or usage_stats["usage_percentage"] > self.aggressive_compression_threshold * 100:
            # 1. Comprimir framework a su m√≠nima expresi√≥n
            framework = compressed_context.get("framework", "")
            if framework and len(framework) > 100:
                # Extraer solo la primera l√≠nea o frase
                compressed_context["framework"] = framework.split('\n')[0].split('.')[0] + '.'
            
            # 2. Reducir dr√°sticamente res√∫menes de cap√≠tulos previos
            prev_summary = compressed_context.get("previous_chapters_summary", "")
            if prev_summary:
                lines = prev_summary.split('\n')
                # Mantener solo la primera l√≠nea de cada cap√≠tulo
                compressed_lines = []
                for line in lines:
                    if line.startswith('-') or line.startswith('‚Ä¢'):
                        parts = line.split(':', 1)
                        if len(parts) > 1:
                            # Tomar solo la primera frase del resumen
                            first_sentence = parts[1].split('.')[0].strip() + '.'
                            compressed_lines.append(f"{parts[0]}: {first_sentence}")
                
                if compressed_lines:
                    compressed_context["previous_chapters_summary"] = "Esencial:\n" + '\n'.join(compressed_lines[:3])
                else:
                    compressed_context["previous_chapters_summary"] = "Esencial: Contin√∫a la historia."
            
            # 3. Reducir contexto de cap√≠tulo actual
            current_summary = compressed_context.get("current_chapter_summary", "")
            if current_summary and len(current_summary) > 100:
                sentences = current_summary.split('.')
                compressed_context["current_chapter_summary"] = sentences[0].strip() + '.'
        
        # Verificar reducci√≥n lograda
        new_usage = self.visualize_token_usage(compressed_context)
        savings = usage_stats["total_tokens"] - new_usage["total_tokens"]
        
        if savings > 0:
            print(f"Compresi√≥n adaptativa aplicada: {savings} tokens ahorrados")
            
        return compressed_context

    def detect_collapse_risk(self, response_text):
        """
        Detecta se√±ales tempranas de que el modelo podr√≠a estar colapsando.
        
        Args:
            response_text: Texto generado por el modelo
            
        Returns:
            tuple: (bool indicando riesgo, mensaje de diagn√≥stico)
        """
        import re
        
        # Si no hay texto o es muy corto, no podemos analizar
        if not response_text or len(response_text) < 20:
            return False, "Texto demasiado corto para analizar"
        
        # Patrones de repetici√≥n que indican colapso
        collapse_patterns = [
            r'(\*\*[^*\n]{1,20})\1{3,}',  # Repetici√≥n de patrones con asteriscos
            r'(Cap√≠tulo\s*\d*\s*:?)\s*\1{2,}',  # Repetici√≥n de "Cap√≠tulo"
            r'([^\n]{5,20})\1{4,}',  # Cualquier fragmento repetido muchas veces
        ]
        
        # Verificar patrones de colapso
        for pattern in collapse_patterns:
            if re.search(pattern, response_text, re.IGNORECASE):
                return True, "Patr√≥n de repetici√≥n detectado: posible colapso de modelo"
        
        # Verificar longitud extremadamente corta (respuesta truncada)
        if len(response_text.strip()) < 50 and "cap√≠tulo" in response_text.lower():
            return True, "Respuesta truncada: posible contexto excesivo"
            
        # Verificar si hay l√≠neas vac√≠as excesivas
        empty_lines = len(re.findall(r'\n\s*\n\s*\n', response_text))
        if empty_lines > 5:
            return True, "Formato degradado: exceso de l√≠neas vac√≠as"
            
        return False, "Sin riesgo detectado"

    def get_minimal_context(self):
        """
        Obtiene un contexto m√≠nimo para recuperar un modelo en riesgo de colapso.
        Solo incluye lo absolutamente esencial.
        
        Returns:
            dict: Contexto ultra m√≠nimo para evitar colapso
        """
        # Para modelos en riesgo, solo regresar lo absolutamente indispensable
        minimal_context = {}
        
        # Extraer datos esenciales del t√≠tulo
        title_essence = self.title.split(':')[0] if ':' in self.title else self.title
        
        # 1. Obtener solo una frase crucial del framework
        framework_essence = ""
        if self.framework:
            framework_lines = self.framework.split('\n')
            if framework_lines:
                for line in framework_lines:
                    if "premisa" in line.lower() or "protagonista" in line.lower():
                        framework_essence = line
                        break
                
                # Si no encontramos l√≠neas con premisa, usar la primera
                if not framework_essence and framework_lines:
                    framework_essence = framework_lines[0]
        
        # 2. Para contexto previo, solo el cap√≠tulo inmediatamente anterior
        previous_context = ""
        if len(self.recent_context_history) > 0:
            # Ordenar por √∫ltimo acceso (0 = m√°s reciente)
            recent_chapters = sorted(
                [(k, v) for k, v in self.recent_context_history.items()],
                key=lambda x: x[1]["last_accessed"]
            )
            
            if recent_chapters:
                chapter_key, data = recent_chapters[0]
                # Extraer solo la primera oraci√≥n
                summary = data["summary"].split('.')[0] + '.' if data["summary"] else ""
                previous_context = f"Anterior: {summary}"
        
        # Construir el contexto m√≠nimo
        minimal_context["framework"] = framework_essence
        minimal_context["previous_chapters_summary"] = previous_context
        minimal_context["position_context"] = "Contin√∫a la narrativa."
        minimal_context["current_chapter_summary"] = ""
            
        return minimal_context
    
    def apply_emergency_compression(self, context_dict):
        """
        Aplica una compresi√≥n de emergencia cuando se detecta riesgo de colapso.
        Mucho m√°s agresiva que la compresi√≥n adaptativa normal.
        
        Args:
            context_dict: Diccionario con componentes del contexto
            
        Returns:
            dict: Contexto ultra-comprimido para recuperar al modelo
        """
        import re
        from utils import print_progress
        
        emergency_context = {}
        
        # 1. Framework: solo conservar 1 oraci√≥n clave
        framework = context_dict.get("framework", "")
        if framework:
            # Buscar la l√≠nea m√°s importante (contiene premisa o protagonista)
            key_line = ""
            for line in framework.split('\n'):
                if "premisa" in line.lower() or "protagonista" in line.lower():
                    key_line = line
                    break
            
            # Si no hay l√≠nea clave, tomar la primera l√≠nea o frase
            if not key_line:
                sentences = framework.split('.')
                key_line = sentences[0] if sentences else framework[:50]
            
            emergency_context["framework"] = key_line[:100].strip() + "."
            
        # 2. Resumen previo: solo mencionar cap√≠tulo anterior si existe
        prev_summary = context_dict.get("previous_chapters_summary", "")
        if prev_summary:
            chapter_mentions = re.findall(r'Cap√≠tulo \d+', prev_summary)
            if chapter_mentions:
                latest_chapter = chapter_mentions[-1]
                emergency_context["previous_chapters_summary"] = f"Contin√∫a desde {latest_chapter}."
            else:
                emergency_context["previous_chapters_summary"] = "Contin√∫a la narrativa anterior."
                
        # 3. Simplificar contexto de posici√≥n
        position = context_dict.get("position_context", "")
        if position:
            emergency_context["position_context"] = position.split('.')[0] + "."
            
        # 4. Eliminar resumen incremental para ahorrar tokens
        emergency_context["current_chapter_summary"] = ""
        
        print_progress("‚ö†Ô∏è APLICANDO COMPRESI√ìN DE EMERGENCIA - RIESGO DE COLAPSO")
        return emergency_context