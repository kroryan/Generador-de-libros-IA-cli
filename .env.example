# Configuración del Generador de Libros IA - Optimizado
# Configuraciones recomendadas para mejor rendimiento y calidad

# ==== CONFIGURACIÓN DE CONTEXTO INTELIGENTE ====
# Habilita el sistema de contexto inteligente que optimiza la memoria
# y mejora el rendimiento con LLMs locales
USE_INTELLIGENT_CONTEXT=true

# Configuración del tamaño de contexto
# "limited" = Optimizado para LLMs locales y modelos pequeños
# "standard" = Para modelos con contexto amplio (GPT-4, Claude, etc.)
MODEL_CONTEXT_SIZE=limited

# ==== CONFIGURACIÓN DE MODELOS ====
# Tipo de modelo por defecto (ollama, openai, groq, deepseek, anthropic)
MODEL_TYPE=ollama

# ==== OLLAMA ====
OLLAMA_API_BASE=http://localhost:11434

# ==== OPENAI ====
# OPENAI_API_KEY=tu_clave_aquí
# OPENAI_API_BASE=https://api.openai.com/v1

# ==== GROQ ====
# GROQ_API_KEY=tu_clave_aquí
# GROQ_AVAILABLE_MODELS=qwen-qwq-32b,llama3-8b-8192,mixtral-8x7b-32768

# ==== DEEPSEEK ====
# DEEPSEEK_API_KEY=tu_clave_aquí
# DEEPSEEK_AVAILABLE_MODELS=deepseek-chat,deepseek-reasoner

# ==== ANTHROPIC ====
# ANTHROPIC_API_KEY=tu_clave_aquí
# ANTHROPIC_AVAILABLE_MODELS=claude-3-opus,claude-3-sonnet,claude-3-haiku

# ==== CONFIGURACIONES AVANZADAS ====
# Configuración de timeouts para APIs
API_TIMEOUT=30

# Configuración de reintentos
MAX_RETRIES=3

# ==== CONFIGURACIÓN DE SALIDA ====
# Formato de salida por defecto (docx, pdf)
DEFAULT_OUTPUT_FORMAT=docx

# Directorio de salida
OUTPUT_DIRECTORY=./docs

# ==== CONFIGURACIÓN DE LOGS ====
# Nivel de logging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ==== CONFIGURACIÓN EXPERIMENTAL ====
# Habilitar features experimentales
ENABLE_EXPERIMENTAL_FEATURES=false

# Configuración de memoria para el contexto inteligente
INTELLIGENT_CONTEXT_MAX_SIZE=2000

# Intervalo de micro-resúmenes (cada N secciones)
MICRO_SUMMARY_INTERVAL=3