"""
Sistema de Contexto Progresivo Inteligente para el Generador de Libros IA.

Este m√≥dulo implementa un sistema avanzado de gesti√≥n de contexto que utiliza
la propia IA para crear res√∫menes inteligentes y mantener la coherencia narrativa
sin sobrecargar los LLMs locales.
"""

from utils import BaseEventChain, print_progress, clean_think_tags, extract_content_from_llm_response
import time

class IntelligentContextManager:
    """
    Gestor de contexto inteligente que usa la IA para resumir autom√°ticamente
    y mantener solo la informaci√≥n esencial entre cap√≠tulos.
    """
    
    def __init__(self, llm, max_context_size=2000):
        self.llm = llm
        self.max_context_size = max_context_size
        self.book_memory = {
            "global_summary": "",
            "characters": {},
            "plot_threads": [],
            "world_building": {},
            "chapter_summaries": {}
        }
        self.current_chapter_content = []
        self.section_count = 0
        
    def add_section_to_chapter(self, section_content, chapter_key):
        """A√±ade una nueva secci√≥n al cap√≠tulo actual"""
        self.current_chapter_content.append(section_content)
        self.section_count += 1
        
        # Cada 3-4 secciones, crear un micro-resumen para evitar acumulaci√≥n
        if self.section_count % 3 == 0:
            self._create_micro_summary(chapter_key)
    
    def _create_micro_summary(self, chapter_key):
        """Crea un micro-resumen de las √∫ltimas secciones para optimizar memoria"""
        if len(self.current_chapter_content) < 3:
            return
            
        print_progress("üîÑ Creando micro-resumen para optimizar contexto...")
        
        # Tomar las √∫ltimas 3 secciones para resumir
        recent_sections = self.current_chapter_content[-3:]
        combined_text = "\n\n".join(recent_sections)
        
        # Crear prompt para micro-resumen
        prompt = f"""
        Resume las siguientes secciones del cap√≠tulo actual manteniendo SOLO los elementos narrativos esenciales.
        M√°ximo 100 palabras, enf√≥cate en:
        - Eventos clave que afectan la trama
        - Desarrollo de personajes importantes
        - Informaci√≥n que ser√° relevante para continuar la historia
        
        IMPORTANTE: Responde SOLO en espa√±ol, m√°ximo 100 palabras.
        
        Secciones a resumir:
        {combined_text[:1500]}
        
        Resumen esencial:
        """
        
        try:
            response = self.llm.invoke(prompt)
            micro_summary = clean_think_tags(extract_content_from_llm_response(response))
            
            # Reemplazar las secciones resumidas con el micro-resumen
            if len(micro_summary) > 20:
                # Mantener solo la √∫ltima secci√≥n completa + el micro-resumen
                self.current_chapter_content = [
                    f"[Resumen de secciones anteriores: {micro_summary}]",
                    self.current_chapter_content[-1]  # √öltima secci√≥n completa
                ]
                print_progress("‚úì Micro-resumen creado, contexto optimizado")
            
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error en micro-resumen: {str(e)}, continuando...")
    
    def finalize_chapter(self, chapter_key, chapter_title, chapter_number, total_chapters):
        """
        Finaliza un cap√≠tulo creando un resumen completo y transfiriendo
        solo la informaci√≥n esencial al contexto global.
        """
        print_progress(f"üìù Finalizando cap√≠tulo {chapter_number}: {chapter_title}")
        
        if not self.current_chapter_content:
            return self._create_fallback_summary(chapter_title, chapter_number)
        
        # Combinar todo el contenido del cap√≠tulo
        full_chapter = "\n\n".join(self.current_chapter_content)
        
        # Crear resumen inteligente del cap√≠tulo completo
        chapter_summary = self._create_intelligent_chapter_summary(
            full_chapter, chapter_title, chapter_number, total_chapters
        )
        
        # Actualizar memoria global
        self._update_global_memory(chapter_summary, chapter_key, chapter_title)
        
        # Limpiar contenido del cap√≠tulo actual
        self.current_chapter_content = []
        self.section_count = 0
        
        return chapter_summary
    
    def _create_intelligent_chapter_summary(self, chapter_content, chapter_title, chapter_number, total_chapters):
        """Crea un resumen inteligente del cap√≠tulo usando IA"""
        
        # Optimizar longitud del contenido si es muy largo
        if len(chapter_content) > 3000:
            # Tomar inicio, medio y final del cap√≠tulo
            start = chapter_content[:1000]
            middle_pos = len(chapter_content) // 2
            middle = chapter_content[middle_pos-500:middle_pos+500]
            end = chapter_content[-1000:]
            
            optimized_content = f"{start}\n\n[...SECCI√ìN MEDIA...]\n\n{middle}\n\n[...SECCI√ìN FINAL...]\n\n{end}"
        else:
            optimized_content = chapter_content
        
        prompt = f"""
        Como editor profesional, crea un resumen estrat√©gico del cap√≠tulo que ser√° usado para mantener 
        coherencia narrativa en los siguientes cap√≠tulos.
        
        IMPORTANTE: 
        - M√°ximo 200 palabras en espa√±ol
        - Enf√≥cate en elementos que afectar√°n cap√≠tulos futuros
        - Incluye personajes, eventos clave, y elementos de trama
        - NO incluyas detalles descriptivos innecesarios
        
        T√≠tulo del libro: [Generaci√≥n en curso]
        Cap√≠tulo: {chapter_title} (Cap√≠tulo {chapter_number} de {total_chapters})
        
        Contenido del cap√≠tulo:
        {optimized_content}
        
        Resumen estrat√©gico para continuidad narrativa:
        """
        
        try:
            response = self.llm.invoke(prompt)
            summary = clean_think_tags(extract_content_from_llm_response(response))
            
            # Validar y limitar longitud
            if len(summary) > 500:
                summary = summary[:500] + "..."
            
            if len(summary) < 30:
                return self._create_fallback_summary(chapter_title, chapter_number)
                
            print_progress(f"‚úì Resumen inteligente del cap√≠tulo {chapter_number} creado ({len(summary)} caracteres)")
            return summary
            
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error en resumen inteligente: {str(e)}")
            return self._create_fallback_summary(chapter_title, chapter_number)
    
    def _create_fallback_summary(self, chapter_title, chapter_number):
        """Crea un resumen b√°sico en caso de error"""
        return f"Cap√≠tulo {chapter_number} ({chapter_title}): La historia contin√∫a desarroll√°ndose."
    
    def _update_global_memory(self, chapter_summary, chapter_key, chapter_title):
        """Actualiza la memoria global del libro con informaci√≥n del nuevo cap√≠tulo"""
        self.book_memory["chapter_summaries"][chapter_key] = {
            "title": chapter_title,
            "summary": chapter_summary,
            "key_elements": self._extract_key_elements(chapter_summary)
        }
        
        # Actualizar resumen global si hay m√∫ltiples cap√≠tulos
        if len(self.book_memory["chapter_summaries"]) > 1:
            self._update_global_summary()
    
    def _extract_key_elements(self, chapter_summary):
        """Extrae elementos clave del resumen (personajes, lugares, eventos)"""
        # Implementaci√≥n b√°sica - puede mejorarse con NLP m√°s avanzado
        key_elements = {
            "characters": [],
            "locations": [],
            "events": []
        }
        
        # An√°lisis simple basado en patrones comunes
        words = chapter_summary.split()
        for i, word in enumerate(words):
            # Buscar nombres propios (palabras que empiezan con may√∫scula)
            if word[0].isupper() and len(word) > 2 and word not in ["El", "La", "Los", "Las", "En", "Con", "Por"]:
                key_elements["characters"].append(word)
        
        return key_elements
    
    def _update_global_summary(self):
        """Actualiza el resumen global del libro basado en todos los cap√≠tulos"""
        if len(self.book_memory["chapter_summaries"]) < 2:
            return
            
        # Crear resumen global combinando res√∫menes de cap√≠tulos
        chapter_summaries = []
        for key, data in self.book_memory["chapter_summaries"].items():
            chapter_summaries.append(f"{data['title']}: {data['summary'][:100]}...")
        
        combined = " | ".join(chapter_summaries)
        
        # Si el resumen global es muy largo, usar IA para condensarlo
        if len(combined) > 800:
            self._condense_global_summary(combined)
        else:
            self.book_memory["global_summary"] = combined
    
    def _condense_global_summary(self, long_summary):
        """Condensa el resumen global usando IA"""
        prompt = f"""
        Condensa el siguiente resumen de la historia manteniendo SOLO los elementos m√°s importantes
        para la coherencia narrativa general. M√°ximo 300 palabras en espa√±ol.
        
        Resumen actual:
        {long_summary}
        
        Resumen condensado:
        """
        
        try:
            response = self.llm.invoke(prompt)
            condensed = clean_think_tags(extract_content_from_llm_response(response))
            
            if len(condensed) > 50:
                self.book_memory["global_summary"] = condensed[:400]
                print_progress("‚úì Resumen global condensado")
            
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error condensando resumen global: {str(e)}")
    
    def get_context_for_next_chapter(self, next_chapter_number):
        """
        Obtiene el contexto optimizado para el siguiente cap√≠tulo.
        Devuelve solo la informaci√≥n esencial sin sobrecargar el LLM.
        """
        context = {
            "global_summary": self.book_memory.get("global_summary", ""),
            "previous_chapter": "",
            "key_characters": [],
            "plot_continuity": ""
        }
        
        # Obtener resumen del cap√≠tulo anterior
        if len(self.book_memory["chapter_summaries"]) > 0:
            last_chapter = list(self.book_memory["chapter_summaries"].values())[-1]
            context["previous_chapter"] = f"{last_chapter['title']}: {last_chapter['summary']}"
        
        # Limitar el contexto total
        total_context = f"{context['global_summary']} {context['previous_chapter']}"
        if len(total_context) > self.max_context_size:
            # Dar prioridad al cap√≠tulo anterior sobre el resumen global
            context["global_summary"] = context["global_summary"][:500] + "..."
        
        return context
    
    def get_current_chapter_context(self):
        """Obtiene el contexto del cap√≠tulo actual para la siguiente secci√≥n"""
        if not self.current_chapter_content:
            return ""
        
        # Devolver las √∫ltimas 1-2 secciones como contexto
        recent_sections = self.current_chapter_content[-2:] if len(self.current_chapter_content) > 2 else self.current_chapter_content
        context = "\n\n".join(recent_sections)
        
        # Limitar longitud
        if len(context) > 800:
            context = context[-800:]
        
        return context


class ProgressiveWriterChain(BaseEventChain):
    """
    Cadena de escritura que utiliza el contexto progresivo inteligente
    """
    
    PROMPT_TEMPLATE = """
    Eres un escritor profesional de {genre} en espa√±ol.
    
    ### INFORMACI√ìN ESENCIAL:
    - T√≠tulo: "{title}"
    - Estilo: {style}
    - Cap√≠tulo actual: {chapter_title} (Cap√≠tulo {current_chapter} de {total_chapters})
    - Secci√≥n: {section_number} de {total_sections}
    
    ### CONTEXTO DE LA HISTORIA:
    {story_context}
    
    ### CONTENIDO RECIENTE DEL CAP√çTULO:
    {recent_content}
    
    ### IDEA A DESARROLLAR:
    {current_idea}
    
    IMPORTANTE: 
    - Escribe EXCLUSIVAMENTE texto narrativo en espa√±ol
    - NO incluyas notas, comentarios ni explicaciones
    - Mant√©n la coherencia con el contexto previo
    - Desarrolla la idea de forma natural y envolvente
    
    Texto narrativo:"""

    def run(self, context_manager, genre, style, title, chapter_title, current_idea, 
            current_chapter, total_chapters, section_number, total_sections):
        
        print_progress(f"üìù Escribiendo secci√≥n {section_number}/{total_sections} (contexto inteligente)")
        
        try:
            # Obtener contexto optimizado
            story_context = context_manager.get_context_for_next_chapter(current_chapter)
            recent_content = context_manager.get_current_chapter_context()
            
            # Crear contexto narrativo condensado
            context_text = ""
            if story_context.get("global_summary"):
                context_text += f"Historia hasta ahora: {story_context['global_summary'][:300]}\n\n"
            if story_context.get("previous_chapter"):
                context_text += f"Cap√≠tulo anterior: {story_context['previous_chapter'][:200]}"
            
            # Generar contenido
            result = self.invoke(
                genre=clean_think_tags(genre),
                style=clean_think_tags(style),
                title=clean_think_tags(title),
                chapter_title=clean_think_tags(chapter_title),
                story_context=clean_think_tags(context_text),
                recent_content=clean_think_tags(recent_content),
                current_idea=clean_think_tags(current_idea),
                current_chapter=current_chapter,
                total_chapters=total_chapters,
                section_number=section_number,
                total_sections=total_sections
            )
            
            print_progress(f"‚úì Secci√≥n {section_number} completada ({len(result)} caracteres)")
            return result

        except Exception as e:
            print_progress(f"‚ùå Error generando secci√≥n {section_number}: {str(e)}")
            # Fallback simple
            return f"La historia continu√≥ desarroll√°ndose en este punto del cap√≠tulo {chapter_title}."