"""
Sistema Unificado de Gesti√≥n de Contexto para el Generador de Libros IA.

Este m√≥dulo consolida los diferentes sistemas de gesti√≥n de contexto:
- ProgressiveContextManager (actualmente en uso)
- IntelligentContextManager (caracter√≠sticas avanzadas no utilizadas)
- MemoryManager (sistema simple no utilizado)
- AdaptiveContextSystem (no funcional)

Proporciona un sistema √∫nico, configurable y extensible para gestionar
el contexto durante la generaci√≥n de libros.
"""

from typing import Dict, List, Optional, Any
from utils import print_progress, clean_think_tags, extract_content_from_llm_response
import os


class ContextMode:
    """Modos de gesti√≥n de contexto disponibles."""
    SIMPLE = "simple"           # Acumulaci√≥n simple de contenido
    PROGRESSIVE = "progressive"  # Sistema progresivo con res√∫menes b√°sicos
    INTELLIGENT = "intelligent"  # Sistema inteligente con micro-res√∫menes autom√°ticos


class UnifiedContextManager:
    """
    Gestor de contexto unificado que combina lo mejor de todos los sistemas anteriores.
    
    Caracter√≠sticas:
    - Gesti√≥n progresiva de contenido de cap√≠tulos (de ProgressiveContextManager)
    - Micro-res√∫menes opcionales autom√°ticos (de IntelligentContextManager)
    - Res√∫menes globales condensados (de IntelligentContextManager)
    - Configuraci√≥n flexible por variables de entorno
    """
    
    def __init__(
        self,
        framework: str = "",
        llm: Optional[Any] = None,
        mode: str = ContextMode.PROGRESSIVE,
        max_context_size: int = 2000,
        enable_micro_summaries: bool = False,
        micro_summary_interval: int = 3
    ):
        """
        Inicializa el gestor de contexto unificado.
        
        Args:
            framework: Marco narrativo general del libro
            llm: Modelo LLM para crear res√∫menes inteligentes (opcional)
            mode: Modo de operaci√≥n (simple, progressive, intelligent)
            max_context_size: Tama√±o m√°ximo del contexto en caracteres
            enable_micro_summaries: Si True, crea micro-res√∫menes autom√°ticos cada N secciones
            micro_summary_interval: N√∫mero de secciones entre micro-res√∫menes
        """
        self.framework = framework
        self.llm = llm
        self.mode = mode
        self.max_context_size = max_context_size
        self.enable_micro_summaries = enable_micro_summaries
        self.micro_summary_interval = micro_summary_interval
        
        # Estructuras de datos
        self.book_context = {}
        self.chapter_contexts: Dict[str, Dict[str, Any]] = {}
        self.global_entities = {}
        self.current_sections = {}
        
        # Para micro-res√∫menes
        self.current_chapter_content: List[str] = []
        self.section_count = 0
        
        # Memoria global (de IntelligentContextManager)
        self.book_memory = {
            "global_summary": "",
            "characters": {},
            "plot_threads": [],
            "world_building": {},
            "chapter_summaries": {}
        }
        
        # Configurar desde variables de entorno si existen
        self._configure_from_env()
    
    def _configure_from_env(self):
        """Configura el gestor desde variables de entorno."""
        mode_env = os.environ.get('CONTEXT_MODE', '').lower()
        if mode_env in [ContextMode.SIMPLE, ContextMode.PROGRESSIVE, ContextMode.INTELLIGENT]:
            self.mode = mode_env
        
        max_size_env = os.environ.get('CONTEXT_MAX_SIZE', '')
        if max_size_env.isdigit():
            self.max_context_size = int(max_size_env)
        
        enable_micro_env = os.environ.get('CONTEXT_ENABLE_MICRO_SUMMARIES', '').lower()
        if enable_micro_env in ['true', '1', 'yes']:
            self.enable_micro_summaries = True
        
        interval_env = os.environ.get('CONTEXT_MICRO_SUMMARY_INTERVAL', '')
        if interval_env.isdigit():
            self.micro_summary_interval = int(interval_env)
    
    # ===== API PRINCIPAL (Compatible con ProgressiveContextManager) =====
    
    def register_chapter(self, chapter_key: str, title: str, summary: str):
        """
        Registra informaci√≥n b√°sica de un cap√≠tulo.
        Compatible con ProgressiveContextManager.
        """
        self.chapter_contexts[chapter_key] = {
            "title": title,
            "summary": summary,
            "content": [],
            "entities": {},
            "section_count": 0
        }
        
        print_progress(f"üìã Cap√≠tulo registrado: {title}")
    
    def update_chapter_content(self, chapter_key: str, section_content: str):
        """
        Actualiza el contenido de un cap√≠tulo con una nueva secci√≥n.
        Compatible con ProgressiveContextManager.
        
        Args:
            chapter_key: Identificador del cap√≠tulo
            section_content: Contenido de la secci√≥n a agregar
        """
        if chapter_key not in self.chapter_contexts:
            self.register_chapter(chapter_key, f"Cap√≠tulo {chapter_key}", "")
        
        if "content" not in self.chapter_contexts[chapter_key]:
            self.chapter_contexts[chapter_key]["content"] = []
        
        # Agregar contenido
        self.chapter_contexts[chapter_key]["content"].append(section_content)
        self.chapter_contexts[chapter_key]["section_count"] += 1
        
        # Gesti√≥n de micro-res√∫menes si est√° habilitado
        if self.enable_micro_summaries and self.llm:
            self.current_chapter_content.append(section_content)
            self.section_count += 1
            
            if self.section_count % self.micro_summary_interval == 0:
                self._create_micro_summary(chapter_key)
    
    def get_context_for_section(
        self,
        chapter_number: int,
        position: str,
        chapter_key: str
    ) -> Dict[str, Any]:
        """
        Obtiene contexto para una secci√≥n espec√≠fica de un cap√≠tulo.
        Compatible con ProgressiveContextManager.
        
        Args:
            chapter_number: N√∫mero del cap√≠tulo actual
            position: Posici√≥n en el cap√≠tulo (inicio, medio, final)
            chapter_key: Identificador del cap√≠tulo
            
        Returns:
            Diccionario con el contexto necesario
        """
        # Si no hay informaci√≥n del cap√≠tulo, devolver contexto vac√≠o
        if chapter_key not in self.chapter_contexts:
            return {
                "framework": self.framework,
                "previous_chapters_summary": "",
                "current_chapter_summary": "",
                "key_entities": {}
            }
        
        # Resumen de cap√≠tulos anteriores
        previous_chapters = []
        for i in range(1, chapter_number):
            for key, ctx in self.chapter_contexts.items():
                # Buscar cap√≠tulos con n√∫mero menor al actual
                if str(i) in key:
                    title = ctx.get("title", f"Cap√≠tulo {key}")
                    summary = ctx.get("summary", "")
                    if summary:
                        previous_chapters.append(f"{title}: {summary}")
        
        # Contenido acumulado del cap√≠tulo actual
        current_content = self.chapter_contexts[chapter_key].get("content", [])
        current_summary = ""
        
        if current_content:
            # Usar las √∫ltimas 3 secciones como contexto
            paragraphs = current_content[-3:] if len(current_content) > 3 else current_content
            current_summary = "\n\n".join(paragraphs)
            
            # Limitar longitud del contexto actual
            if len(current_summary) > self.max_context_size:
                current_summary = current_summary[-self.max_context_size:]
        
        return {
            "framework": self.framework,
            "previous_chapters_summary": " ".join(previous_chapters),
            "current_chapter_summary": current_summary,
            "key_entities": self.global_entities.get(chapter_key, {})
        }
    
    # ===== CARACTER√çSTICAS AVANZADAS (De IntelligentContextManager) =====
    
    def _create_micro_summary(self, chapter_key: str):
        """
        Crea un micro-resumen de las √∫ltimas secciones para optimizar memoria.
        Caracter√≠stica de IntelligentContextManager.
        """
        if not self.llm or len(self.current_chapter_content) < self.micro_summary_interval:
            return
        
        print_progress("üîÑ Creando micro-resumen para optimizar contexto...")
        
        # Tomar las √∫ltimas N secciones para resumir
        recent_sections = self.current_chapter_content[-self.micro_summary_interval:]
        combined_text = "\n\n".join(recent_sections)
        
        # Crear prompt para micro-resumen
        prompt = f"""
        Resume las siguientes secciones del cap√≠tulo actual manteniendo SOLO los elementos narrativos esenciales.
        M√°ximo 100 palabras, enf√≥cate en:
        - Eventos clave que afectan la trama
        - Desarrollo de personajes importantes
        - Informaci√≥n que ser√° relevante para continuar la historia
        
        IMPORTANTE: Responde SOLO en espa√±ol, m√°ximo 100 palabras.
        
        Secciones a resumir:
        {combined_text[:1500]}
        
        Resumen esencial:
        """
        
        try:
            response = self.llm.invoke(prompt)
            micro_summary = clean_think_tags(extract_content_from_llm_response(response))
            
            # Reemplazar las secciones resumidas con el micro-resumen
            if len(micro_summary) > 20:
                # Mantener solo la √∫ltima secci√≥n completa + el micro-resumen
                self.current_chapter_content = [
                    f"[Resumen de secciones anteriores: {micro_summary}]",
                    self.current_chapter_content[-1]  # √öltima secci√≥n completa
                ]
                print_progress("‚úì Micro-resumen creado, contexto optimizado")
        
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error en micro-resumen: {str(e)}, continuando...")
    
    def finalize_chapter(
        self,
        chapter_key: str,
        chapter_title: str,
        chapter_number: int,
        total_chapters: int
    ) -> str:
        """
        Finaliza un cap√≠tulo creando un resumen completo.
        Caracter√≠stica de IntelligentContextManager.
        
        Returns:
            Resumen del cap√≠tulo finalizado
        """
        print_progress(f"üìù Finalizando cap√≠tulo {chapter_number}: {chapter_title}")
        
        if chapter_key not in self.chapter_contexts or not self.chapter_contexts[chapter_key].get("content"):
            return self._create_fallback_summary(chapter_title, chapter_number)
        
        # Si no hay LLM, usar el resumen b√°sico
        if not self.llm:
            return self.chapter_contexts[chapter_key].get("summary", 
                self._create_fallback_summary(chapter_title, chapter_number))
        
        # Crear resumen inteligente del cap√≠tulo completo
        full_chapter = "\n\n".join(self.chapter_contexts[chapter_key]["content"])
        chapter_summary = self._create_intelligent_chapter_summary(
            full_chapter, chapter_title, chapter_number, total_chapters
        )
        
        # Actualizar memoria global
        self._update_global_memory(chapter_summary, chapter_key, chapter_title)
        
        # Limpiar contenido del cap√≠tulo actual
        self.current_chapter_content = []
        self.section_count = 0
        
        return chapter_summary
    
    def _create_intelligent_chapter_summary(
        self,
        chapter_content: str,
        chapter_title: str,
        chapter_number: int,
        total_chapters: int
    ) -> str:
        """Crea un resumen inteligente del cap√≠tulo usando IA."""
        
        # Optimizar longitud del contenido si es muy largo
        if len(chapter_content) > 3000:
            start = chapter_content[:1000]
            middle_pos = len(chapter_content) // 2
            middle = chapter_content[middle_pos-500:middle_pos+500]
            end = chapter_content[-1000:]
            
            optimized_content = f"{start}\n\n[...SECCI√ìN MEDIA...]\n\n{middle}\n\n[...SECCI√ìN FINAL...]\n\n{end}"
        else:
            optimized_content = chapter_content
        
        prompt = f"""
        Como editor profesional, crea un resumen estrat√©gico del cap√≠tulo que ser√° usado para mantener 
        coherencia narrativa en los siguientes cap√≠tulos.
        
        IMPORTANTE: 
        - M√°ximo 200 palabras en espa√±ol
        - Enf√≥cate en elementos que afectar√°n cap√≠tulos futuros
        - Incluye personajes, eventos clave, y elementos de trama
        - NO incluyas detalles descriptivos innecesarios
        
        Cap√≠tulo: {chapter_title} (Cap√≠tulo {chapter_number} de {total_chapters})
        
        Contenido del cap√≠tulo:
        {optimized_content}
        
        Resumen estrat√©gico para continuidad narrativa:
        """
        
        try:
            response = self.llm.invoke(prompt)
            summary = clean_think_tags(extract_content_from_llm_response(response))
            
            # Validar y limitar longitud
            if len(summary) > 500:
                summary = summary[:500] + "..."
            
            if len(summary) < 30:
                return self._create_fallback_summary(chapter_title, chapter_number)
            
            print_progress(f"‚úì Resumen inteligente del cap√≠tulo {chapter_number} creado ({len(summary)} caracteres)")
            return summary
        
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error en resumen inteligente: {str(e)}")
            return self._create_fallback_summary(chapter_title, chapter_number)
    
    def _create_fallback_summary(self, chapter_title: str, chapter_number: int) -> str:
        """Crea un resumen b√°sico en caso de error."""
        return f"Cap√≠tulo {chapter_number} ({chapter_title}): La historia contin√∫a desarroll√°ndose."
    
    def _update_global_memory(self, chapter_summary: str, chapter_key: str, chapter_title: str):
        """Actualiza la memoria global del libro con informaci√≥n del nuevo cap√≠tulo."""
        self.book_memory["chapter_summaries"][chapter_key] = {
            "title": chapter_title,
            "summary": chapter_summary,
            "key_elements": {}
        }
        
        # Actualizar resumen global si hay m√∫ltiples cap√≠tulos
        if len(self.book_memory["chapter_summaries"]) > 1:
            self._update_global_summary()
    
    def _update_global_summary(self):
        """Actualiza el resumen global del libro basado en todos los cap√≠tulos."""
        if len(self.book_memory["chapter_summaries"]) < 2:
            return
        
        # Crear resumen global combinando res√∫menes de cap√≠tulos
        chapter_summaries = []
        for key, data in self.book_memory["chapter_summaries"].items():
            chapter_summaries.append(f"{data['title']}: {data['summary'][:100]}...")
        
        combined = " | ".join(chapter_summaries)
        
        # Si el resumen global es muy largo y hay LLM, condensarlo
        if len(combined) > 800 and self.llm:
            self._condense_global_summary(combined)
        else:
            self.book_memory["global_summary"] = combined
    
    def _condense_global_summary(self, long_summary: str):
        """Condensa el resumen global usando IA."""
        if not self.llm:
            return
        
        prompt = f"""
        Condensa el siguiente resumen de la historia manteniendo SOLO los elementos m√°s importantes
        para la coherencia narrativa general. M√°ximo 300 palabras en espa√±ol.
        
        Resumen actual:
        {long_summary}
        
        Resumen condensado:
        """
        
        try:
            response = self.llm.invoke(prompt)
            condensed = clean_think_tags(extract_content_from_llm_response(response))
            
            if len(condensed) > 50:
                self.book_memory["global_summary"] = condensed[:400]
                print_progress("‚úì Resumen global condensado")
        
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error condensando resumen global: {str(e)}")
    
    def get_context_for_next_chapter(self, next_chapter_number: int) -> Dict[str, Any]:
        """
        Obtiene el contexto optimizado para el siguiente cap√≠tulo.
        Caracter√≠stica de IntelligentContextManager.
        """
        context = {
            "global_summary": self.book_memory.get("global_summary", ""),
            "previous_chapter": "",
            "key_characters": [],
            "plot_continuity": ""
        }
        
        # Obtener resumen del cap√≠tulo anterior
        if len(self.book_memory["chapter_summaries"]) > 0:
            last_chapter = list(self.book_memory["chapter_summaries"].values())[-1]
            context["previous_chapter"] = f"{last_chapter['title']}: {last_chapter['summary']}"
        
        # Limitar el contexto total
        total_context = f"{context['global_summary']} {context['previous_chapter']}"
        if len(total_context) > self.max_context_size:
            # Dar prioridad al cap√≠tulo anterior sobre el resumen global
            context["global_summary"] = context["global_summary"][:500] + "..."
        
        return context
    
    def get_current_chapter_context(self) -> str:
        """Obtiene el contexto del cap√≠tulo actual para la siguiente secci√≥n."""
        if not self.current_chapter_content:
            return ""
        
        # Devolver las √∫ltimas 1-2 secciones como contexto
        recent_sections = (self.current_chapter_content[-2:] 
                          if len(self.current_chapter_content) > 2 
                          else self.current_chapter_content)
        context = "\n\n".join(recent_sections)
        
        # Limitar longitud
        if len(context) > 800:
            context = context[-800:]
        
        return context


# ===== ALIAS PARA COMPATIBILIDAD =====

# Mantener compatibilidad con c√≥digo existente que usa ProgressiveContextManager
ProgressiveContextManager = UnifiedContextManager
