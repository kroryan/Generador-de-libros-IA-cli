# Configuración de APIs para generación de libros con IA
# ======================================================

# CONFIGURACIÓN GENERAL
# --------------------
# Tipo de modelo predeterminado a utilizar
MODEL_TYPE=ollama

# CONFIGURACIÓN DE OLLAMA (PRIORIDAD 1)
# -------------------------------------
# Especifica el modelo de Ollama a utilizar
OLLAMA_MODEL=gemma3:latest
# API base de Ollama - para uso local
OLLAMA_API_BASE=http://localhost:11434

# CONFIGURACIÓN DE DEEPSEEK (PRIORIDAD 2)
# ---------------------------------------
# Clave API de DeepSeek
# https://platform.deepseek.com/api
DEEPSEEK_API_KEY=
# Modelo de DeepSeek a utilizar: 'deepseek-chat' o 'deepseek-reasoner'
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_API_BASE=https://api.deepseek.com

# CONFIGURACIÓN DE OPENAI (PRIORIDAD 3)
# -------------------------------------
# Clave API de OpenAI
# https://platform.openai.com/account/api-keys
OPENAI_API_KEY=
# Modelo de OpenAI a utilizar (gpt-3.5-turbo, gpt-4, etc.)
OPENAI_MODEL=gpt-3.5-turbo
# URL base para APIs compatibles con OpenAI (deja en blanco para usar la API oficial de OpenAI)
OPENAI_API_BASE=https://api.openai.com/v1

# CONFIGURACIÓN DE GROQ
# --------------------
# Clave API de Groq lo puedes configurar para cualquier api open ai compatible
# https://console.groq.com/keys
GROQ_API_KEY=
# Modelo de Groq a utilizar - usando un modelo más pequeño para evitar problemas de contexto
GROQ_MODEL=qwen/qwen3-8b-fp8

# URL base de la API de Groq
GROQ_API_BASE=https://api.novita.ai/v3/openai
# Lista de modelos disponibles en Groq (separados por comas)
GROQ_AVAILABLE_MODELS=qwen-qwq-32b,llama3-8b-8192,deepseek/deepseek-r1-distill-llama-8b,gemma2-9b-it,qwen/qwen2.5-7b-instruct,qwen/qwen3-8b-fp8

# Importante: configuración para manejo de modelos con contexto limitado
MODEL_CONTEXT_SIZE=limited

# Deshabilitar health check temporalmente para debug
PROVIDER_HEALTH_CHECK_ENABLED=false

# CONFIGURACIÓN DE ANTHROPIC
# -------------------------
# Clave API de Anthropic
# https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=
# Modelo de Anthropic a utilizar
ANTHROPIC_MODEL=claude-3-opus
# URL base de la API de Anthropic
ANTHROPIC_API_BASE=https://api.anthropic.com/v1
# Lista de modelos disponibles en Anthropic (separados por comas)
ANTHROPIC_AVAILABLE_MODELS=claude-3-opus,claude-3-sonnet,claude-3-haiku

# Puedes añadir más proveedores personalizados siguiendo el mismo formato:
# NOMBRE_PROVEEDOR_API_KEY=tu_api_key
# NOMBRE_PROVEEDOR_MODEL=nombre_modelo
# NOMBRE_PROVEEDOR_API_BASE=url_base
# NOMBRE_PROVEEDOR_AVAILABLE_MODELS=modelo1,modelo2,modelo3