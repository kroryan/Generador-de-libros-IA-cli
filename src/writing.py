from utils import BaseEventChain, print_progress, clean_think_tags, extract_content_from_llm_response, BaseChain
from chapter_summary import ChapterSummaryChain, ProgressiveContextManager
from emergency_prompts import emergency_prompts
from example_library import ExampleLibrary
from section_quality_monitor import SectionQualityMonitor
from time import sleep
import re
import time  # Importaci√≥n a√±adida para usar time.sleep()
import os    # Importaci√≥n a√±adida para variables de entorno

# FASE 4: Importar configuraci√≥n centralizada
from config.defaults import get_config

# Obtener configuraci√≥n
_config = get_config()
_context_config = _config.context
_rate_limit_config = _config.rate_limit

class WriterChain(BaseEventChain):
    # Template zero-shot original
    ZERO_SHOT_TEMPLATE = """
    Eres un escritor profesional de {genre} en espa√±ol.
    
    ### INFORMACI√ìN ESENCIAL:
    - T√≠tulo: "{title}"
    - Estilo: {style}
    - Cap√≠tulo actual: {chapter_title} (Cap√≠tulo {current_chapter} de {total_chapters})
    - Posici√≥n: {section_position} del cap√≠tulo
    
    ### CONTEXTO RESUMIDO:
    {summary}
    
    ### P√ÅRRAFOS RECIENTES:
    {previous_paragraphs}
    
    ### IDEA A DESARROLLAR AHORA:
    {current_idea}
    
    <think>
    Desarrollar√© esta idea enfoc√°ndome solo en:
    1. Conexi√≥n directa con el contenido reciente
    2. Desarrollo coherente de personajes y situaciones
    3. Avance natural de la historia
    
    Mantendr√© el foco narrativo sin divagar ni resumir.
    </think>
    
    IMPORTANTE: 
    - Escribe EXCLUSIVAMENTE texto narrativo en espa√±ol
    - NO incluyas notas, comentarios ni explicaciones
    - Solo genera el texto que formar√≠a parte del libro final
    
    Escribe directamente el contenido narrativo:"""

    # Nuevo template few-shot con ejemplos
    FEW_SHOT_TEMPLATE = """
    Eres un escritor profesional de {genre} en espa√±ol.
    
    ### INFORMACI√ìN ESENCIAL:
    - T√≠tulo: "{title}"
    - Estilo: {style}
    - Cap√≠tulo actual: {chapter_title} (Cap√≠tulo {current_chapter} de {total_chapters})
    - Posici√≥n: {section_position} del cap√≠tulo
    
    ### EJEMPLOS DE REFERENCIA:
    
    A continuaci√≥n se muestran ejemplos de secciones bien escritas en este g√©nero/estilo:
    
    {examples}
    
    ### CONTEXTO RESUMIDO:
    {summary}
    
    ### P√ÅRRAFOS RECIENTES:
    {previous_paragraphs}
    
    ### IDEA A DESARROLLAR AHORA:
    {current_idea}
    
    <think>
    Analizar√© los ejemplos para capturar:
    1. Tono y ritmo narrativo caracter√≠stico del g√©nero
    2. Nivel de detalle descriptivo apropiado
    3. Balance entre acci√≥n, di√°logo y descripci√≥n
    4. T√©cnicas de transici√≥n entre escenas
    
    Luego desarrollar√© la idea actual manteniendo:
    - Conexi√≥n directa con el contenido reciente
    - Desarrollo coherente de personajes y situaciones
    - Avance natural de la historia
    - Calidad similar a los ejemplos mostrados
    </think>
    
    IMPORTANTE: 
    - Escribe EXCLUSIVAMENTE texto narrativo en espa√±ol
    - Mant√©n el nivel de calidad de los ejemplos mostrados
    - NO incluyas notas, comentarios ni explicaciones
    - Solo genera el texto que formar√≠a parte del libro final
    
    Escribe directamente el contenido narrativo:"""
    
    def __init__(self, use_few_shot: bool = True):
        """
        Args:
            use_few_shot: Si True, usa prompts con ejemplos. Si False, usa zero-shot.
        """
        super().__init__()
        
        # NUEVO: Configurar few-shot learning
        self.use_few_shot = use_few_shot
        if self.use_few_shot:
            self.example_library = ExampleLibrary()
            self.PROMPT_TEMPLATE = self.FEW_SHOT_TEMPLATE
        else:
            self.PROMPT_TEMPLATE = self.ZERO_SHOT_TEMPLATE

    def run(
        self,
        genre,
        style,
        title,
        context_manager,
        chapter_title,
        summary,
        previous_paragraphs,
        current_idea,
        current_chapter,
        total_chapters,
        section_position,
        section_number,
        total_sections,
        chapter_key
    ):
        print_progress(f"Escribiendo secci√≥n {section_number}/{total_sections} del cap√≠tulo {current_chapter}")
        
        try:
            # Limpiar todas las entradas de posibles cadenas de pensamiento
            summary_clean = clean_think_tags(summary)
            previous_paragraphs_clean = clean_think_tags(previous_paragraphs)
            current_idea_clean = clean_think_tags(current_idea)
            
            # FASE 4: Usar configuraci√≥n en lugar de valores m√°gicos
            # Optimizar longitud del contexto para evitar sobrecarga
            if len(previous_paragraphs_clean) > _context_config.limited_context_size:
                previous_paragraphs_clean = previous_paragraphs_clean[-_context_config.limited_context_size:] 
            
            # NUEVO: Obtener ejemplos relevantes si few-shot est√° activado
            examples_text = ""
            if self.use_few_shot:
                examples_text = self._get_formatted_examples(
                    genre=genre,
                    style=style,
                    section_position=section_position
                )
            
            # Invocar con o sin ejemplos seg√∫n configuraci√≥n
            invoke_params = {
                'genre': clean_think_tags(genre),
                'style': clean_think_tags(style),
                'title': clean_think_tags(title),
                'chapter_title': clean_think_tags(chapter_title),
                'summary': summary_clean,
                'previous_paragraphs': previous_paragraphs_clean,
                'current_idea': current_idea_clean,
                'current_chapter': current_chapter,
                'total_chapters': total_chapters,
                'section_position': section_position,
                'section_number': section_number,
                'total_sections': total_sections
            }
            
            # Solo a√±adir ejemplos si estamos usando few-shot
            if self.use_few_shot:
                invoke_params['examples'] = examples_text
            
            result = self.invoke(**invoke_params)
            
            # El resultado ya viene limpio por el invoke() de BaseChain
            print_progress(f"Secci√≥n completada: {len(result)} caracteres")
            return result

        except Exception as e:
            print_progress(f"Error generando contenido: {str(e)}")
            raise
    
    def _get_formatted_examples(
        self, 
        genre: str, 
        style: str, 
        section_position: str
    ) -> str:
        """
        Recupera y formatea ejemplos relevantes para el prompt.
        
        Args:
            genre: G√©nero del libro
            style: Estilo de escritura
            section_position: inicio/medio/final
            
        Returns:
            String formateado con 1-2 ejemplos
        """
        try:
            # Obtener n√∫mero m√°ximo de ejemplos desde configuraci√≥n
            max_examples = _config.few_shot.max_examples_per_prompt
            
            # Obtener ejemplos de la biblioteca
            examples = self.example_library.get_examples(
                genre=genre,
                style=style,
                section_type=section_position,
                max_examples=max_examples
            )
            
            if not examples:
                # Fallback: buscar sin filtro de tipo
                examples = self.example_library.get_examples(
                    genre=genre,
                    style=style,
                    max_examples=max_examples
                )
            
            if not examples:
                return "[No hay ejemplos disponibles para este g√©nero/estilo]"
            
            # Formatear ejemplos para el prompt
            formatted = []
            for i, ex in enumerate(examples, 1):
                formatted.append(f"""
**EJEMPLO {i}:**

Contexto previo:
{ex.context}

Idea desarrollada:
{ex.idea}

Texto generado:
{ex.content}

---
""")
            
            return "\n".join(formatted)
            
        except Exception as e:
            print_progress(f"‚ö†Ô∏è Error obteniendo ejemplos: {str(e)}")
            return "[Error cargando ejemplos]"

def regenerate_problematic_section(writer_chain, context_manager, section_params, max_attempts=3):
    """
    Intenta regenerar una secci√≥n que ha mostrado problemas o se√±ales de colapso.
    Ahora usa el sistema centralizado de prompts de emergencia.
    """
    print_progress("üîÑ Intentando regenerar secci√≥n problem√°tica...")
    
    # Extractores de par√°metros clave
    chapter_key = section_params.get('chapter_key', 'cap√≠tulo actual')
    chapter_title = section_params.get('chapter_title', 'este cap√≠tulo')
    current_idea = section_params.get('current_idea', '')
    
    try:
        # Usar prompt de emergencia centralizado en lugar de l√≥gica de reintentos manual
        emergency_prompt = emergency_prompts.get_section_regeneration_prompt(
            context_summary=f"Cap√≠tulo: {chapter_title}",
            previous_content=section_params.get('previous_paragraphs', '')[:200]
        )
        
        # Ejecutar con el sistema de reintentos integrado en BaseChain
        response = writer_chain.llm.invoke(emergency_prompt)
        content = clean_think_tags(extract_content_from_llm_response(response))
        
        if content and len(content.strip()) > 50:
            print_progress("‚úÖ Regeneraci√≥n exitosa usando prompt de emergencia")
            return content
            
    except Exception as e:
        print_progress(f"Error en regeneraci√≥n con prompt de emergencia: {str(e)}")
    
    # Si todo falla, usar texto de contingencia
    print_progress("‚ö†Ô∏è Usando texto de contingencia tras fallo de regeneraci√≥n")
    return f"La escena continu√≥ desarroll√°ndose. Los personajes avanzaron en su objetivo mientras exploraban {chapter_title}."

def create_savepoint_summary(llm, title, chapter_num, chapter_title, current_summary, new_section, total_chapters=None):
    """
    Sistema simplificado y aut√≥nomo para crear res√∫menes incrementales como puntos de guardado.
    No depende de ChapterSummaryChain, evitando as√≠ los errores de par√°metros faltantes.
    """
    print_progress(f"Actualizando resumen del cap√≠tulo {chapter_num} para savepoint...")
    
    try:
        # Si no hay resumen previo, crear uno b√°sico
        if not current_summary or current_summary.strip() == "":
            current_summary = f"Inicio del cap√≠tulo {chapter_num}: {chapter_title}"
        
        # Si la nueva secci√≥n es muy larga, limitarla para el an√°lisis
        if len(new_section) > 1500:
            summary_section = new_section[:750] + "\n\n[...]\n\n" + new_section[-750:]
        else:
            summary_section = new_section
            
        # Prompt directo y simple para generar el resumen
        prompt = f"""
        Actualiza el resumen existente para incorporar solo los elementos esenciales 
        de la nueva secci√≥n. Mant√©n el resumen muy breve y centrado solo en lo crucial.
        
        IMPORTANTE: M√°ximo 150 palabras, solo en espa√±ol.
        
        T√≠tulo: {clean_think_tags(title)}
        Cap√≠tulo: {clean_think_tags(chapter_title)} (Cap√≠tulo {chapter_num})
        
        Resumen actual:
        {clean_think_tags(current_summary)}
        
        Nueva secci√≥n:
        {clean_think_tags(summary_section)}
        
        Resumen actualizado:
        """
        
        # Usar directamente el LLM para evitar problemas con las clases de resumen
        # BaseChain ahora maneja los reintentos autom√°ticamente, eliminamos l√≥gica manual
        try:
            # Invocar directamente al modelo - los reintentos est√°n en BaseChain
            result = llm.invoke(prompt)
            # Extraer y limpiar la respuesta
            text_result = extract_content_from_llm_response(result)
            updated_summary = clean_think_tags(text_result)
            
            # Verificar si el resultado es v√°lido
            if updated_summary and len(updated_summary) > 20:
                # Limitar la longitud para evitar res√∫menes excesivamente largos
                if len(updated_summary) > 500:
                    updated_summary = updated_summary[:500] + "..."
                return updated_summary
            else:
                # Si no hay resultado v√°lido, usar prompt de emergencia
                emergency_prompt = emergency_prompts.get_summary_emergency_prompt(new_section[:300])
                emergency_result = llm.invoke(emergency_prompt)
                return clean_think_tags(extract_content_from_llm_response(emergency_result))
                    
        except Exception as e:
            print_progress(f"Error creando resumen: {str(e)}")
            # Usar prompt de emergencia como fallback
            try:
                emergency_prompt = emergency_prompts.get_summary_emergency_prompt(new_section[:300])
                emergency_result = llm.invoke(emergency_prompt)
                return clean_think_tags(extract_content_from_llm_response(emergency_result))
            except:
                # Si todo falla, devolver el resumen actual sin cambios
                print_progress("No se pudo generar un nuevo resumen, manteniendo el actual")
                return current_summary
        
        # Si todos los intentos fallan, devolver el resumen actual sin cambios
        print_progress("No se pudo generar un nuevo resumen, manteniendo el actual")
        return current_summary
        
    except Exception as e:
        print_progress(f"Error creando savepoint: {str(e)}")
        return current_summary  # En caso de error, devolver el resumen anterior

def write_book(genre, style, profile, title, framework, summaries_dict, idea_dict, chapter_summaries=None):
    print_progress("Iniciando escritura del libro...")
    
    # NUEVO: Usar configuraci√≥n centralizada para few-shot learning
    config = _config
    few_shot_config = config.few_shot
    
    # Inicializar monitor de calidad con configuraci√≥n
    quality_monitor = SectionQualityMonitor(
        quality_threshold=few_shot_config.quality_threshold,
        auto_save=few_shot_config.auto_save_examples
    )
    
    # Inicializar WriterChain con configuraci√≥n few-shot
    writer_chain = WriterChain(use_few_shot=few_shot_config.enabled)
    book = {}
    
    # Si no hay res√∫menes de cap√≠tulos, crear un diccionario vac√≠o
    if chapter_summaries is None:
        chapter_summaries = {}

    # NUEVO: Inicializar el gestor de contexto con sistema din√°mico
    try:
        from dynamic_context import DynamicContextCalculator, ModelContextProfile
        
        # Intentar detectar el modelo desde variables de entorno
        model_type = os.environ.get("MODEL_TYPE", "ollama")
        model_name = "unknown"
        
        # Crear calculador din√°mico
        context_calc = DynamicContextCalculator(model_name, model_type)
        
        # Inicializar contexto manager con perfil din√°mico y LLM
        context_manager = ProgressiveContextManager(
            framework=framework,
            llm=writer_chain.llm,  # Pasar LLM para micro-res√∫menes
            enable_micro_summaries=True,  # Activar micro-res√∫menes
            micro_summary_interval=3,     # Cada 3 secciones
            model_profile=context_calc.profile
        )
        
        print_progress("üß† Sistema de contexto din√°mico inicializado")
        
    except Exception as e:
        print_progress(f"‚ö†Ô∏è Error inicializando contexto din√°mico: {e}")
        print_progress("üîÑ Usando sistema de contexto tradicional")
        context_manager = ProgressiveContextManager(framework)
    
    summary_chain = ChapterSummaryChain()

    try:
        total_chapters = len(idea_dict)
        
        # Usar sistema inteligente de ordenamiento O(n log n)
        from chapter_ordering import sort_chapters_intelligently
        ordered_chapters = sort_chapters_intelligently(idea_dict)
        
        # Procesar cap√≠tulos en el orden establecido
        for i, chapter in enumerate(ordered_chapters, 1):
            idea_list = idea_dict[chapter]
            
            print_progress(f"======================================")
            print_progress(f"CAP√çTULO {i}/{total_chapters}: {chapter}")
            print_progress(f"======================================")
            
            book[chapter] = []
            ideas_total = len(idea_list)
            chapter_content = []
            
            # Obtener resumen del cap√≠tulo
            chapter_summary = summaries_dict.get(chapter, "")
            
            # Registrar el cap√≠tulo en el gestor de contexto
            context_manager.register_chapter(chapter, chapter, chapter_summary)
            
            # Acumular texto para contexto
            paragraphs_context = ""
            
            # Crear un resumen incremental que se actualizar√° durante la escritura
            savepoint_summary = f"Inicio del cap√≠tulo {i}: {chapter}"
            
            # Definir intervalo para puntos de guardado (cada cu√°ntas ideas se crea un savepoint)
            savepoint_interval = max(1, min(3, ideas_total // 3))  # Al menos 3 savepoints por cap√≠tulo
            
            for j, idea in enumerate(idea_list, 1):
                # Determinar posici√≥n en el cap√≠tulo
                section_position = "medio"
                if j == 1:
                    section_position = "inicio"
                elif j == ideas_total:
                    section_position = "final"
                
                # Mostrar parte de la idea en la consola
                idea_preview = idea[:40] + "..." if len(idea) > 40 else idea
                print_progress(f">> Idea {j}/{ideas_total}: {idea_preview}")
                
                # SISTEMA DE SAVEPOINTS: Verificar si toca crear un punto de guardado
                is_savepoint = (j == 1 or j == ideas_total or j % savepoint_interval == 0)
                
                if is_savepoint and paragraphs_context:
                    try:
                        print_progress("üìå Creando punto de guardado (savepoint)...")
                        # Usar nuestra nueva funci√≥n independiente que no requiere de ChapterSummaryChain
                        savepoint_summary = create_savepoint_summary(
                            llm=writer_chain.llm,
                            title=title,
                            chapter_num=i,
                            chapter_title=chapter,
                            current_summary=savepoint_summary,
                            new_section=paragraphs_context[-1500:] if len(paragraphs_context) > 1500 else paragraphs_context,
                            total_chapters=total_chapters
                        )
                        print_progress("‚úì Punto de guardado creado")
                        
                        # Cada ciertos savepoints (2-3), limpiar el contexto acumulado para evitar sobrecarga
                        if j > savepoint_interval * 2:
                            # Mantener solo las √∫ltimas 2-3 secciones y reemplazar el resto con el resumen
                            recent_sections = chapter_content[-2:] if len(chapter_content) > 2 else chapter_content
                            paragraphs_context = f"[Resumen hasta ahora: {savepoint_summary}]\n\n" + "\n\n".join(recent_sections)
                            print_progress("üßπ Contexto optimizado para continuar")
                    except Exception as e:
                        print_progress(f"‚ö†Ô∏è Error creando savepoint: {str(e)}")
                        # Si ocurre un error al crear el savepoint, seguir adelante con el resumen actual
                        # Esto garantiza que un error en el resumen no interrumpa la generaci√≥n del libro
                
                # Preparar los par√°metros para la generaci√≥n de contenido
                section_params = {
                    'genre': genre,
                    'style': style,
                    'title': title,
                    'context_manager': context_manager,
                    'chapter_title': chapter,
                    'summary': chapter_summary if j == 1 else savepoint_summary,  # Usar resumen incremental
                    # FASE 4: Usar configuraci√≥n en lugar de valor m√°gico 800
                    'previous_paragraphs': paragraphs_context[-_context_config.limited_context_size:] if paragraphs_context else "",
                    'current_idea': idea,
                    'current_chapter': i,
                    'total_chapters': total_chapters,
                    'section_position': section_position,
                    'section_number': j,
                    'total_sections': ideas_total,
                    'chapter_key': chapter
                }
                
                # Usar un sistema simplificado sin reintentos manuales
                try:
                    # Usar BaseChain que ya tiene reintentos integrados
                    section_content = writer_chain.run(**section_params)
                    
                    # Verificar si el contenido es v√°lido
                    if section_content and len(section_content.strip()) >= 50:
                        pass  # Contenido v√°lido, continuar
                    else:
                        # Si el contenido no es v√°lido, usar prompt de emergencia
                        emergency_prompt = emergency_prompts.get_writing_emergency_prompt(
                            chapter_title=chapter,
                            idea=idea[:100]
                        )
                        raw_response = writer_chain.llm.invoke(emergency_prompt)
                        section_content = clean_think_tags(extract_content_from_llm_response(raw_response))
                
                except Exception as e:
                    print_progress(f"Error en generaci√≥n: {str(e)}")
                    # Usar prompt de emergencia como fallback
                    emergency_prompt = emergency_prompts.get_writing_emergency_prompt(
                        chapter_title=chapter,
                        idea=idea[:100]
                    )
                    try:
                        raw_response = writer_chain.llm.invoke(emergency_prompt)
                        section_content = clean_think_tags(extract_content_from_llm_response(raw_response))
                    except:
                        # √öltimo recurso: texto de respaldo
                        section_content = f"La historia continu√≥ desarroll√°ndose en {chapter}. Los personajes avanzaron en su objetivo mientras enfrentaban nuevos desaf√≠os."
                
                # Si despu√©s de todos los intentos no hay contenido v√°lido, usar texto de respaldo
                if not section_content or len(section_content.strip()) < 50:
                    print_progress("‚ö†Ô∏è Usando texto de respaldo tras m√∫ltiples fallos")
                    section_content = f"La historia continu√≥ desarroll√°ndose en {chapter}. Los personajes avanzaron en su objetivo mientras enfrentaban nuevos desaf√≠os."
                
                # NUEVO: Evaluar y potencialmente guardar como ejemplo
                quality_score = quality_monitor.evaluate_and_store(
                    section_content=section_content,
                    genre=genre,
                    style=style,
                    section_position=section_position,
                    context=paragraphs_context[-200:] if paragraphs_context else "",
                    idea=idea,
                    book_title=title
                )
                
                if quality_score:
                    print_progress(f"üìä Calidad de secci√≥n: {quality_score:.2f}")
                
                # Actualizar contexto en el gestor y guardar el contenido
                context_manager.update_chapter_content(chapter, section_content)
                
                # FASE 4: Usar configuraci√≥n en lugar de valores m√°gicos 5000/3000
                # Actualizar contexto acumulado (limitar para evitar sobrecarga)
                if len(paragraphs_context) > _context_config.max_context_accumulation:
                    # Mantener solo la parte m√°s reciente
                    paragraphs_context = paragraphs_context[-_context_config.standard_context_size:]
                    
                # A√±adir nuevo contenido al contexto
                paragraphs_context += "\n\n" + section_content
                
                # Guardar el contenido generado
                chapter_content.append(section_content)
                book[chapter].append(section_content)
                
                # FASE 4: Usar rate limiting de configuraci√≥n
                # Peque√±a pausa entre secciones para evitar problemas con APIs
                time.sleep(_rate_limit_config.default_delay)
            
            # Al finalizar el cap√≠tulo, generar un resumen completo para usar en el siguiente cap√≠tulo
            try:
                chapter_complete_text = "\n\n".join(chapter_content)
                chapter_summaries[chapter] = summary_chain.run(
                    title=title,
                    chapter_num=i,
                    chapter_title=chapter,
                    chapter_content=chapter_complete_text,
                    total_chapters=total_chapters
                )
                print_progress(f"‚úì Resumen final del cap√≠tulo {i} generado")
            except Exception as e:
                print_progress(f"‚ö†Ô∏è Error generando resumen final: {str(e)}")
                chapter_summaries[chapter] = savepoint_summary
            
            # NUEVO: Mostrar reporte din√°mico al finalizar el cap√≠tulo
            try:
                if hasattr(context_manager, 'get_dynamic_status'):
                    dynamic_status = context_manager.get_dynamic_status()
                    if dynamic_status.get('dynamic_enabled', False):
                        complexity_report = dynamic_status.get('complexity_report', {})
                        quality_report = dynamic_status.get('quality_report', {})
                        
                        print_progress("üìä REPORTE DIN√ÅMICO DEL CAP√çTULO:")
                        if complexity_report.get('overall_complexity'):
                            print_progress(f"   Complejidad narrativa: {complexity_report['complexity_category']} "
                                         f"({complexity_report['overall_complexity']:.2f})")
                            entities = complexity_report.get('entities', {})
                            print_progress(f"   Personajes detectados: {entities.get('character_count', 0)}")
                            print_progress(f"   Ubicaciones detectadas: {entities.get('location_count', 0)}")
                        
                        if quality_report.get('average_quality'):
                            print_progress(f"   Calidad de res√∫menes: {quality_report['quality_category']} "
                                         f"({quality_report['average_quality']:.2f})")
                            print_progress(f"   Factor de agresividad: {quality_report['aggressiveness_factor']:.1f}x")
                        
                        current_limits = dynamic_status.get('current_limits', {})
                        if current_limits:
                            print_progress(f"   L√≠mites din√°micos actuales:")
                            print_progress(f"     - Secci√≥n: {current_limits.get('max_section_context', 'N/A')} chars")
                            print_progress(f"     - Cap√≠tulo: {current_limits.get('max_chapter_context', 'N/A')} chars")
            except Exception as e:
                print_progress(f"‚ö†Ô∏è Error mostrando reporte din√°mico: {e}")
            
            print_progress(f"‚úì Cap√≠tulo {chapter} completado: {len(chapter_content)} secciones")

        # Al final de la generaci√≥n, mostrar estad√≠sticas de calidad
        stats = quality_monitor.get_session_stats()
        print_progress("\n" + "="*50)
        print_progress("üìà ESTAD√çSTICAS DE FEW-SHOT LEARNING:")
        print_progress(f"  Secciones evaluadas: {stats['sections_evaluated']}")
        print_progress(f"  Secciones guardadas como ejemplos: {stats['sections_saved']}")
        print_progress(f"  Calidad promedio: {stats['average_quality']:.2f}")
        print_progress(f"  Calidad m√°xima: {stats['max_quality']:.2f}")
        print_progress(f"  Calidad m√≠nima: {stats['min_quality']:.2f}")
        print_progress(f"  Tasa de guardado: {stats['save_rate']:.1%}")
        print_progress("="*50 + "\n")
        
        print_progress("======================================")
        print_progress("ESCRITURA DEL LIBRO FINALIZADA")
        print_progress("======================================")
        return book

    except Exception as e:
        print_progress(f"Error general en la escritura del libro: {str(e)}")
        raise  # Propagar el error para detener la ejecuci√≥n

def optimize_prompt_for_limited_context(prompt, max_length=None, preserve_instructions=True):
    """
    Versi√≥n simplificada que no modifica los prompts.
    Todos los modelos reciben el prompt completo sin optimizaciones.
    """
    # Devolver el prompt original sin modificaciones
    return prompt

def extract_first_sentence(text):
    """Extrae la primera frase de un texto"""
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return sentences[0] if sentences else ""

def extract_last_sentence(text):
    """Extrae la √∫ltima frase de un texto"""
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return sentences[-1] if sentences else ""
